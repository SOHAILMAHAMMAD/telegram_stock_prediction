{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries: pip install telethon pandas scikit-learn nltk\n",
    "\n",
    "from telethon.sync import TelegramClient\n",
    "from telethon.sessions import MemorySession\n",
    "from telethon.tl.functions.messages import GetHistoryRequest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "api_id = '' # provide api_id\n",
    "api_hash = '' # provide hash value\n",
    "channel_username = '' # provide channel_name\n",
    "\n",
    "\n",
    "# Updated Scraping function using MemorySession to avoid database locking\n",
    "async def scrape_telegram_data(api_id, api_hash, channel_username, limit=500, keywords=['stock', 'market', 'price']):\n",
    "    async with TelegramClient('session_name', api_id, api_hash) as client:\n",
    "        # This will prompt for phone number and authentication\n",
    "        await client.start()\n",
    "\n",
    "        messages = []\n",
    "        history = await client(GetHistoryRequest(\n",
    "            peer=channel_username,\n",
    "            limit=limit,\n",
    "            offset_date=None,\n",
    "            offset_id=0,\n",
    "            max_id=0,\n",
    "            min_id=0,\n",
    "            add_offset=0,\n",
    "            hash=0))\n",
    "\n",
    "        for message in history.messages:\n",
    "            if message.message and any(keyword in message.message.lower() for keyword in keywords):\n",
    "                messages.append(message.message)\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "# Preprocess and extract features\n",
    "def preprocess_and_extract_features(messages):\n",
    "    data = pd.DataFrame({'message': messages})\n",
    "\n",
    "    # Sentiment analysis\n",
    "    data['sentiment'] = data['message'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "    # Message length as a feature\n",
    "    data['length'] = data['message'].apply(len)\n",
    "\n",
    "    # Label generation (dummy labels for demonstration; replace with real data if available)\n",
    "    data['label'] = np.random.choice([0, 1], size=len(data))\n",
    "\n",
    "    return data\n",
    "\n",
    "# Build and evaluate the prediction model\n",
    "def train_and_evaluate_model(data):\n",
    "    X = data[['sentiment', 'length']]\n",
    "    y = data['label']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Model training with RandomForestClassifier\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Model prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Scrape data\n",
    "    messages = await scrape_telegram_data(api_id, api_hash, channel_username)\n",
    "\n",
    "    # Step 2: Preprocess and extract features\n",
    "    data = preprocess_and_extract_features(messages)\n",
    "\n",
    "    # Step 3: Train and evaluate the model\n",
    "    model, metrics = train_and_evaluate_model(data)\n",
    "\n",
    "    # Output model evaluation metrics\n",
    "    print(\"Model Evaluation Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
